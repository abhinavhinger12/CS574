{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9lm-5s0IZEm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Vrin5jOIZEp"
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "inter = 56\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeFohO4TIZEr"
   },
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./files', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./files', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4eMH1bgKIZEu",
    "outputId": "3bd85d8b-0f39-4154-ed86-980abc4d3962",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pQraNXASO5k"
   },
   "outputs": [],
   "source": [
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XK2Ga6EAIZEx"
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RT16qA75IZEy"
   },
   "outputs": [],
   "source": [
    "class MLP1linear(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP1linear, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, inter)\n",
    "        self.fc2 = nn.Linear(inter, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc2(self.fc1(x))\n",
    "        return out\n",
    "      \n",
    "class MLP1relu(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP1relu, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, inter)\n",
    "        self.fc2 = nn.Linear(inter, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return out\n",
    "      \n",
    "class MLP1tanh(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP1tanh, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, inter)\n",
    "        self.fc2 = nn.Linear(inter, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.fc2(F.tanh(self.fc1(x))))\n",
    "        return out\n",
    "\n",
    "      \n",
    "class MLP2linear(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP2linear, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 300)\n",
    "        self.fc2 = nn.Linear(300, inter)\n",
    "        self.fc3 = nn.Linear(inter, num_classes)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc3(self.fc2(self.fc1(x)))\n",
    "        return out\n",
    "\n",
    "      \n",
    "class MLP2relu(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP2relu, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 300)\n",
    "        self.fc2 = nn.Linear(300, inter)\n",
    "        self.fc3 = nn.Linear(inter, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc3(F.relu(self.fc2(F.relu(self.fc1(x))))))\n",
    "        return out\n",
    "      \n",
    "class MLP2tanh(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(MLP2tanh, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 300)\n",
    "        self.fc2 = nn.Linear(300, inter)\n",
    "        self.fc3 = nn.Linear(inter, num_classes)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.fc3(F.tanh(self.fc2(F.tanh(self.fc1(x))))))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN1c(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1440, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1440)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN2c(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "class CNN1ck3(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(1690, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1690)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "class CNN1ck5(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1440, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1440)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN1ck7(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=7)\n",
    "        self.fc1 = nn.Linear(1210, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1210)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN2cLinear(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (F.max_pool2d(self.conv1(x), 2))\n",
    "        x = (F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = (self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN2cTanh(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.tanh(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN2cSigmoid(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.sigmoid(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN1cNK5(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(720, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 720)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN1cNK10(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1440, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 1440)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "class CNN1cNK20(nn.Module):\n",
    "    def __init__(self, input_size, inter,num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(2880, 320)\n",
    "        self.fc2 = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, 2880)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofv3r483Xs2J"
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(test_loader,device,model,criterion):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  test_loss = []\n",
    "  for images, labels in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      images = Variable(images.view(-1, 28*28))\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum()\n",
    "      test_loss.append(loss.item())\n",
    "  \n",
    "  return (int( (100 * correct / total))),mean(test_loss)\n",
    "      \n",
    "\n",
    "\n",
    "def runner(input_size, inter, num_classes, filename,train_loader, test_loader,learning_rate,device,num_epochs,momentum,model_class,criterion):\n",
    "  model = model_class(input_size, inter, num_classes)\n",
    "  model.to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "  training_losses = []\n",
    "  accuracy = []\n",
    "  test_loss = []\n",
    "  accuracy_test = []\n",
    "  for epoch in range(num_epochs):\n",
    "      correct = 0\n",
    "      train_loss = []\n",
    "      total = 0\n",
    "      for i, (images, labels) in enumerate(train_loader):\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          images = Variable(images.view(-1, 28*28))\n",
    "          labels = Variable(labels)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "          total += labels.size(0)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          correct += (predicted==labels).sum()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          train_loss.append(loss.item())\n",
    "      acc, lo = test(test_loader,device,model,criterion)\n",
    "      test_loss.append(lo)\n",
    "      training_losses.append(mean(train_loss))\n",
    "      accuracy_test.append(acc)\n",
    "      accuracy.append(int( (100 * correct / total)))\n",
    "      \n",
    "\n",
    "#   accuracy = int( (100 * correct / total))\n",
    "  fig = plt.figure()\n",
    "  plt.plot(range(len(training_losses)+1)[1:], training_losses)\n",
    "  plt.plot(range(len(test_loss)+1)[1:], test_loss)\n",
    "  plt.title('Loss vs Epoch - ' + str(filename))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.savefig(str(filename) + ' loss vs epoch.png')\n",
    "  plt.clf()\n",
    "  fig = plt.figure()\n",
    "  plt.plot(range(len(accuracy)+1)[1:], accuracy)\n",
    "  plt.plot(range(len(accuracy_test)+1)[1:], accuracy_test)\n",
    "  plt.title('Accuracy vs Epoch - ' + str(filename))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.savefig(str(filename) + ' accuracy vs epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "9VDbN6wtIZE0",
    "outputId": "eef61a02-c9e0-4ee6-b2cc-c9fb4b93a4e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKzE/X+RwL8Tqh5sCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner(784,56,10,'MLP 1 Hidden Layer',train_loader,test_loader,learning_rate,device,num_epochs,momentum,MLP1linear,nn.CrossEntropyLoss())\n",
    "# runner(784,56,10,2,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP1relu,nn.CrossEntropyLoss())\n",
    "# runner(784,56,10,3,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP1tanh,nn.CrossEntropyLoss())\n",
    "# runner(784,56,10,4,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP2linear,nn.CrossEntropyLoss())\n",
    "# runner(784,56,10,5,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP2relu,nn.CrossEntropyLoss())\n",
    "# runner(784,56,10,6,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP2tanh,nn.CrossEntropyLoss())\n",
    "# runner(784,140,10,7,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP1relu,nn.CrossEntropyLoss())\n",
    "\n",
    "\n",
    "# runner(784,56,10,2,train_loader,test_loader,learning_rate,device,num_epochs,0.9,MLP_non_linear,nn.CrossEntropyLoss())\n",
    "# runner(784,148,10,3,train_loader,test_loader,learning_rate,device,num_epochs,0.5,MLP_non_linear,nn.CrossEntropyLoss())\n",
    "# runner(784,148,10,4,train_loader,test_loader,learning_rate,device,num_epochs,0.9,MLP_non_linear,nn.CrossEntropyLoss())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWzy4LO0Pwsy"
   },
   "outputs": [],
   "source": [
    "# # Downloading all the graphs\n",
    "# from google.colab import files\n",
    "# files.download('1 accuracy vs epoch.png')\n",
    "# files.download('1 loss vs epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Z7fynh3VTOn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
